# DDS Development Guidelines

This document defines the standard practices for DDS application development in this framework. These guidelines apply to all code generated by AI models during benchmarks unless explicitly directed otherwise.

## Core Principles

### 0. Test Early and Test Often (Critical)

**This is the most important principle.** Do not write large amounts of code before testing.

#### Required Testing Cadence

1. **After creating any file**: Verify it loads without syntax errors
   ```bash
   timeout 5 python -c "import my_module" && echo "OK"
   ```

2. **After implementing a function**: Test it with simple inputs
   ```bash
   timeout 5 python -c "from my_module import my_func; print(my_func(test_input))"
   ```

3. **After creating a CLI**: Verify `--help` works
   ```bash
   timeout 5 python my_cli.py --help
   ```

4. **Before integration**: Test each component individually

5. **Always use timeouts**: Commands can hang indefinitely (especially DDS)
   ```bash
   timeout 30 python publisher.py --domain 99
   ```

#### Why This Matters

- **Catching errors early** is exponentially cheaper than debugging integrated systems
- **DDS applications can hang** waiting for discovery or data - always use timeouts
- **AI models cannot observe real-time output** - hung processes block indefinitely
- **Incremental testing** builds confidence and reduces debugging scope

#### Anti-Pattern (DO NOT DO THIS)

```
# BAD: Writing 500 lines across 10 files, then testing
write file1.py (100 lines)
write file2.py (100 lines)
write file3.py (100 lines)
write file4.py (100 lines)
write file5.py (100 lines)
# Finally test... and it fails somewhere
python main.py  # Where is the bug? Could be anywhere in 500 lines
```

#### Correct Pattern

```
# GOOD: Test after each meaningful addition
write file1.py (core function)
timeout 5 python -c "from file1 import func; print(func(1))"  # Test immediately

write file1.py (add second function)  
timeout 5 python -c "from file1 import func2; print(func2('test'))"  # Test immediately

write file2.py (depends on file1)
timeout 5 python -c "from file2 import main; main()"  # Test integration
```

#### Todo-Driven Testing

When using a todo list, **every completed todo should have a verification test** when possible:

```
TODO: Implement spy_parser.py
  → Complete todo
  → TEST: timeout 5 python -c "from spy_parser import SpyParser; print('OK')"
  → TEST: timeout 5 python -m pytest tests/test_spy_parser.py -v

TODO: Build CLI wrapper
  → Complete todo
  → TEST: timeout 5 python cli.py --help
  → TEST: timeout 10 python cli.py --domain 99 --timeout 5

TODO: Create QoS XML file
  → Complete todo  
  → TEST: timeout 5 python -c "import rti.connextdds as dds; dds.QosProvider('qos.xml'); print('OK')"
```

Some todos have prerequisites or post-requisites for testing:
- **Prerequisites**: Todo B requires Todo A to be complete and tested first
- **Post-requisites**: Todo C can only be fully tested after Todo D provides test data

Document these dependencies explicitly and test as early as the dependency chain allows.

### 1. Asynchronous Readers with Callbacks (Required)

**DO NOT use polling for DDS readers.** All DDS subscribers must use asynchronous callbacks via `on_data_available` or WaitSet patterns.

#### Correct Pattern (WaitSet with Condition)
```python
import rti.connextdds as dds

# Create reader
reader = dds.DynamicData.DataReader(subscriber, topic)

# Set up status condition for DATA_AVAILABLE
status_condition = dds.StatusCondition(reader)
status_condition.enabled_statuses = dds.StatusMask.DATA_AVAILABLE

# Create WaitSet and attach condition
waitset = dds.WaitSet()
waitset.attach_condition(status_condition)

# Async wait loop (NOT polling)
while running:
    conditions = waitset.wait(dds.Duration.from_seconds(1.0))
    if status_condition in conditions:
        samples = reader.take()
        for sample in samples:
            if sample.info.valid:
                process_sample(sample.data)
```

#### Incorrect Pattern (Polling - DO NOT USE)
```python
# BAD: Busy polling wastes CPU and is not responsive
while running:
    samples = reader.take()  # Polling!
    time.sleep(0.1)  # Arbitrary delay
```

### 2. External QoS Configuration (Required)

**QoS settings must be in external XML files**, not hardcoded in application code.

#### QoS XML File Structure
```xml
<?xml version="1.0" encoding="UTF-8"?>
<dds xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
     xsi:noNamespaceSchemaLocation="http://community.rti.com/schema/current/rti_dds_qos_profiles.xsd">
    
    <qos_library name="MyLibrary">
        <qos_profile name="DefaultProfile" is_default_qos="true">
            
            <datawriter_qos>
                <reliability>
                    <kind>RELIABLE_RELIABILITY_QOS</kind>
                </reliability>
                <history>
                    <kind>KEEP_LAST_HISTORY_QOS</kind>
                    <depth>10</depth>
                </history>
            </datawriter_qos>
            
            <datareader_qos>
                <reliability>
                    <kind>RELIABLE_RELIABILITY_QOS</kind>
                </reliability>
            </datareader_qos>
            
        </qos_profile>
    </qos_library>
    
</dds>
```

#### Loading QoS in Code
```python
import rti.connextdds as dds

# Load QoS from external file
qos_provider = dds.QosProvider("qos_profiles.xml")

# Use QoS from provider
participant = dds.DomainParticipant(domain_id, qos_provider.participant_qos)
writer = dds.DynamicData.DataWriter(publisher, topic, qos_provider.datawriter_qos)
reader = dds.DynamicData.DataReader(subscriber, topic, qos_provider.datareader_qos)
```

### 3. Timeout Protection (Required)

**All DDS operations must have timeout protection** to prevent indefinite blocking.

```python
# Set max_blocking_time in QoS XML
<datawriter_qos>
    <reliability>
        <max_blocking_time>
            <sec>1</sec>
            <nanosec>0</nanosec>
        </max_blocking_time>
    </reliability>
</datawriter_qos>

# Use timeouts in WaitSet
conditions = waitset.wait(dds.Duration.from_seconds(timeout))

# Use timeouts for command-line operations
timeout 30 python publisher.py
```

### 4. DynamicData vs IDL-Generated Types

Use DynamicData when:
- Type definitions come from XML at runtime
- Flexibility is needed for adapters/bridges
- Working with unknown or variable types

Use IDL-generated types when:
- Types are known at compile time
- Maximum performance is required
- Type safety is critical

### 5. Domain ID Selection

- Use domain IDs between 0-232 (higher values cause RTPS port overflow)
- For testing, use domain IDs 50-99 to avoid conflicts
- Never hardcode domain ID 0 in tests (may conflict with other DDS applications)

```python
from dds_tools.core.port_utils import get_safe_domain_id

domain_id = get_safe_domain_id()  # Returns available ID in safe range
```

### 6. Resource Cleanup

Always properly close DDS entities:

```python
# Use context managers when available
with dds.DomainParticipant(domain_id) as participant:
    # ... use participant ...
# Automatically cleaned up

# Or explicit cleanup
try:
    # ... DDS operations ...
finally:
    participant.close()  # Ensure cleanup
```

### 7. Error Handling

Log all DDS errors with context:

```python
try:
    writer.write(sample)
except dds.Error as e:
    logging.error(f"Failed to write sample to topic {topic_name}: {e}")
    raise
```

---

## Benchmark-Specific Requirements

When AI models generate DDS code for benchmarks, the following requirements apply unless the benchmark prompt explicitly states otherwise:

### Default Requirements (Always Apply)

| Requirement | Description |
|-------------|-------------|
| **Test Early, Test Often** | Verify each component immediately after writing - do not batch |
| **Always Use Timeouts** | Every command must use `timeout N` - DDS can hang indefinitely |
| Async Callbacks | Use WaitSet/on_data_available, NOT polling |
| External QoS | Load QoS from XML file, NOT hardcoded |
| Domain ID | Use safe range (50-99) or accept as parameter |
| Cleanup | Proper resource cleanup on exit |
| Error Logging | Log errors with context |

### Override Syntax

Benchmark prompts may override defaults with explicit instructions:

```
"Create a subscriber that uses polling instead of callbacks"
"Hardcode QoS settings for this example (no external XML)"
"Use domain ID 0 specifically"
```

### Verification Criteria

Generated code will be verified against these criteria:

1. **No polling loops** - grep for `while.*reader.take()` without WaitSet
2. **External QoS** - Check for `QosProvider` usage or explicit QoS file loading
3. **Timeouts present** - Verify timeout parameters in WaitSet and QoS
4. **Proper cleanup** - Check for close() calls or context managers

---

## Quick Reference

### Minimum Viable Subscriber
```python
import rti.connextdds as dds

def run_subscriber(domain_id: int, qos_file: str, timeout: float):
    # Load external QoS
    qos_provider = dds.QosProvider(qos_file)
    
    # Create participant with QoS
    participant = dds.DomainParticipant(domain_id, qos_provider.participant_qos)
    
    # Create type, topic, subscriber, reader
    my_type = create_type()
    topic = dds.DynamicData.Topic(participant, "MyTopic", my_type)
    subscriber = dds.Subscriber(participant)
    reader = dds.DynamicData.DataReader(subscriber, topic, qos_provider.datareader_qos)
    
    # Async wait with WaitSet (NOT polling)
    status_condition = dds.StatusCondition(reader)
    status_condition.enabled_statuses = dds.StatusMask.DATA_AVAILABLE
    waitset = dds.WaitSet()
    waitset.attach_condition(status_condition)
    
    start = time.time()
    while time.time() - start < timeout:
        conditions = waitset.wait(dds.Duration.from_seconds(1.0))
        if status_condition in conditions:
            for sample in reader.take():
                if sample.info.valid:
                    process(sample.data)
```

### Minimum Viable Publisher
```python
import rti.connextdds as dds

def run_publisher(domain_id: int, qos_file: str, count: int, rate: float):
    # Load external QoS
    qos_provider = dds.QosProvider(qos_file)
    
    # Create participant with QoS
    participant = dds.DomainParticipant(domain_id, qos_provider.participant_qos)
    
    # Create type, topic, publisher, writer
    my_type = create_type()
    topic = dds.DynamicData.Topic(participant, "MyTopic", my_type)
    publisher = dds.Publisher(participant)
    writer = dds.DynamicData.DataWriter(publisher, topic, qos_provider.datawriter_qos)
    
    # Publish samples
    sample = dds.DynamicData(my_type)
    for i in range(count):
        sample["field"] = i
        writer.write(sample)
        time.sleep(1.0 / rate)
```

